# tcmturkiye.py
# tcm_scraper_automation.py

"""
Otomatik TCM (Geleneksel Ã‡in TÄ±bbÄ±) bilgi sistemi mimarisi
AmaÃ§: PubMed Ã¼zerinden akupunkturla ilgili en yeni makaleleri tek tek Ã§ekmek,
      her seferinde yeni bir makale iÅŸlemek,
      Ã¶zet Ã§Ä±karmak, gÃ¶rsel Ã¼retmek ve yayÄ±nlanabilir iÃ§erik formatÄ± oluÅŸturmak.
"""

import logging
import requests
import datetime
import os
import sys
from dotenv import load_dotenv
load_dotenv()
from typing import List, Dict

# PubMed XML ayrÄ±ÅŸtÄ±rma
from tcmturkiye.pubmed_parser import parse_pubmed_xml
# GPT tabanlÄ± iÃ§erik fonksiyonlarÄ±
from tcmturkiye.content_builder import (
    generate_summary,
    classify_article,
    generate_commentary,
    translate_title
)
# index oluÅŸturma (Ã¶rneÄŸin, index-tr.html / index-en.html)
from tcmturkiye.generate_index import generate_index_html
# DALLÂ·E API ile gÃ¶rsel Ã¼retimi
from tcmturkiye.image_generator import generate_image
# Markdown dosyalarÄ± yazma
from tcmturkiye.markdown_writer import (
    save_markdown,
    build_markdown_content_tr,
    build_markdown_content_en
)

# -- GPT ve DALLÂ·E iÃ§in OpenAI baÄŸlantÄ±sÄ±
import openai

# Loglama konfigÃ¼rasyonu: INFO seviyesinde log alacak ve zaman damgasÄ± ekleyecek.
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s %(levelname)s: %(message)s',
    datefmt='%Y-%m-%d %H:%M:%S'
)

# Ayarlar
openai.api_key = os.getenv("OPENAI_API_KEY")

SEARCH_TERM = "acupuncture"
# Bu kod tek bir makale Ã§ekmeye Ã§alÄ±ÅŸacak
RETMAX_SINGLE = 1

def get_pubmed_articles_single(query: str, retstart: int = 0) -> str:
    """
    PubMed'den, belirtilen arama terimiyle tek bir makale (retmax=1) Ã§eker.
    retstart parametresi sÄ±ralamada ileri gitmeyi saÄŸlar.
    Geriye XML verisi dÃ¶ndÃ¼rÃ¼r.
    """
    base_url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi"
    params = {
        "db": "pubmed",
        "term": query,
        "retmode": "json",
        "retmax": RETMAX_SINGLE,  # 1 sonuÃ§
        "retstart": retstart,
        "sort": "pub date"
    }
    response = requests.get(base_url, params=params)
    id_list = response.json()["esearchresult"]["idlist"]
    if not id_list:
        # HiÃ§ sonuÃ§ dÃ¶nmediyse boÅŸ string verelim
        return ""

    # Makale detaylarÄ±nÄ± al
    fetch_url = "https://eutils.ncbi.nlm.nih.gov/entrez/eutils/efetch.fcgi"
    fetch_params = {
        "db": "pubmed",
        "id": ",".join(id_list),
        "retmode": "xml"
    }
    fetch_response = requests.get(fetch_url, params=fetch_params)
    return fetch_response.text

if __name__ == "__main__":
    logging.info("ğŸ” Yeni bir makale aranÄ±yor...")

    # Daha Ã¶nce iÅŸlenmiÅŸ PMID'leri tutan dosya
    processed_ids_file = "processed_pmids.txt"
    if not os.path.exists(processed_ids_file):
        open(processed_ids_file, "w").close()

    with open(processed_ids_file, "r", encoding="utf-8") as f:
        processed_ids = set(line.strip() for line in f if line.strip())

    retstart = 0
    new_article_found = False
    max_tries = 50  # Ã§ok sayÄ±da deneme hakkÄ±

    while not new_article_found and max_tries > 0:
        max_tries -= 1
        # Tek makale XML'i Ã§ek
        xml_data = get_pubmed_articles_single(SEARCH_TERM, retstart=retstart)
        if not xml_data.strip():
            logging.info(f"âŒ Makale bulunamadÄ± veya retstart={retstart} iÃ§in sonuÃ§ yok.")
            retstart += 1
            continue

        with open("pubmed_raw.xml", "w", encoding="utf-8") as f:
            f.write(xml_data)
        logging.info("ğŸ“„ pubmed_raw.xml dosyasÄ±na veri yazÄ±ldÄ±.")

        articles = parse_pubmed_xml(xml_data)
        if len(articles) == 0:
            logging.info(f"âŒ parse_pubmed_xml ile makale bulunamadÄ± (retstart={retstart}).")
            retstart += 1
            continue

        # Tek makale
        article = articles[0]
        pmid = article.get("pmid", "PMID bulunamadÄ±")
        if pmid == "PMID bulunamadÄ±":
            logging.error("âŒ PMID alÄ±namadÄ±, bu makale atlanÄ±yor.")
            retstart += 1
            continue

        if pmid in processed_ids:
            logging.info(f"Bu makale zaten iÅŸlenmiÅŸ (PMID={pmid}). Sonraki retstart={retstart+1}")
            retstart += 1
            continue

        # Yeni makale bulundu!
        new_article_found = True
        logging.info(f"âœ… Yeni makale bulundu: PMID={pmid}")
        article["url"] = f"https://pubmed.ncbi.nlm.nih.gov/{pmid}/"

        logging.info("ğŸ·ï¸ Makale kategorilendiriliyor...")
        article["categories"] = classify_article(article["title"], article["abstract"])

        logging.info(f"âœï¸ Ã–zet hazÄ±rlanÄ±yor: {article['title']}")
        summary_parts = generate_summary(article["title"], article["abstract"])
        article["summary_tr"] = summary_parts.get("summary_tr", "")
        article["summary_en"] = summary_parts.get("summary_en", "")

        logging.info("ğŸ§  Yorum oluÅŸturuluyor...")
        commentary_raw = generate_commentary(article["title"], article["abstract"])
        # Ã–rnek Ã§Ä±ktÄ±: \"##TR## ... \\n##EN## ...\"
        commentary_parts = commentary_raw.split("##EN##")
        commentary_tr = commentary_parts[0].replace("##TR##", "").strip()
        commentary_en = commentary_parts[1].strip() if len(commentary_parts) > 1 else ""
        article["commentary_tr"] = commentary_tr
        article["commentary_en"] = commentary_en

        logging.info("ğŸ”¤ BaÅŸlÄ±k TÃ¼rkÃ§eye Ã§evriliyor...")
        article["title_tr"] = translate_title(article["title"], target_lang="tr")

        logging.info("ğŸ¨ GÃ¶rsel Ã¼retiliyor...")
        image_url = generate_image(article["title"] + " acupuncture medical illustration")
        article["image_path"] = image_url

        logging.info("ğŸ“„ Markdown formatÄ± hazÄ±rlanÄ±yor (TR & EN)...")
        # TÃ¼rkÃ§e iÃ§erik
        markdown_tr = build_markdown_content_tr(
            title=article["title_tr"],
            authors=article.get("authors", []),
            abstract=article["abstract"],
            summary_tr=article["summary_tr"],
            commentary_tr=article["commentary_tr"],
            image_path=article["image_path"],
            pubmed_url=article["url"],
            categories=article["categories"],
            tags=[]
        )
        save_markdown(article, markdown_tr, language="tr")

        # Ä°ngilizce iÃ§erik
        markdown_en = build_markdown_content_en(
            title=article["title"],
            authors=article.get("authors", []),
            abstract=article["abstract"],
            summary_en=article["summary_en"],
            commentary_en=article["commentary_en"],
            image_path=article["image_path"],
            pubmed_url=article["url"],
            categories=article["categories"],
            tags=[]
        )
        save_markdown(article, markdown_en, language="en")

        logging.info("ğŸ’¾ Markdown olarak kaydedildi.")

        # Makale iÅŸlem bitti, PMID kaydedelim
        processed_ids.add(pmid)
        with open(processed_ids_file, "a", encoding="utf-8") as ff:
            ff.write(pmid + "\n")

    # DÃ¶ngÃ¼den Ã§Ä±kÄ±nca index.html gÃ¼ncellenebilir
    if new_article_found:
        generate_index_html()
        logging.info("âœ… TÃ¼m iÅŸlemler tamamlandÄ±.")
    else:
        logging.info("ğŸ’¡ Yeni makale bulunamadÄ±; muhtemelen arama sonuÃ§larÄ± tÃ¼kendi veya limit aÅŸÄ±ldÄ±.")